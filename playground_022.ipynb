{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOARImg7etut/YndwUeBhXq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ueki5/colaboratory/blob/main/playground_022.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchviz | tail -n 1\n",
        "!pip install torchinfo | tail -n 1\n",
        "!pip install japanize-matplotlib | tail -n 1\n",
        "!pip install plotly | tail -n 1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "ljFG6GVDBoaC",
        "outputId": "a7cd4b1b-3def-4006-8255-ad9fc0311993"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully installed torchviz-0.0.3\n",
            "Successfully installed torchinfo-1.8.0\n",
            "Successfully installed japanize-matplotlib-1.1.3\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from plotly) (25.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datetime import datetime\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import japanize_matplotlib\n",
        "japanize_matplotlib.japanize()\n",
        "from tqdm.notebook import tqdm\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.transforms as transforms\n",
        "from torchviz import make_dot\n",
        "\n",
        "# 各種定数\n",
        "batch_size = 500 # ミニバッチのサイズ指定\n",
        "num_epochs = 10 # 繰り返し回数\n",
        "lr = 0.01  # 学習率\n",
        "dim_hidden = 128 # 隠れ層の次元数\n",
        "dim_output = 10 # 出力層の次元数\n",
        "num_layer = 2 # レイヤー数\n",
        "use_cuda = True # CUDA使用\n",
        "\n",
        "# デバイスの割り当て\n",
        "if use_cuda:\n",
        "  device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "else:\n",
        "  device = torch.device(\"cpu\")\n",
        "print(device)\n",
        "\n",
        "# ダウンロード先ディレクトリ名\n",
        "data_root = './data'\n",
        "# テンソル化 ＋ 正規化\n",
        "transform = transforms.Compose([\n",
        "  # データのテンソル化\n",
        "  transforms.ToTensor(),\n",
        "  # データの正規化(Normalize(μ, σ) ⇒ (x - μ) / σ)\n",
        "  transforms.Normalize(0.5, 0.5),\n",
        "])\n",
        "# 訓練データ\n",
        "train_set = datasets.CIFAR10(\n",
        "  root=data_root,\n",
        "  train=True,\n",
        "  download=True,\n",
        "  transform=transform\n",
        ")\n",
        "# 検証データ\n",
        "test_set = datasets.CIFAR10(\n",
        "  root=data_root,\n",
        "  train=False,\n",
        "  download=True,\n",
        "  transform=transform\n",
        ")\n",
        "# データ変換結果の確認\n",
        "print('# 入力データの確認')\n",
        "image, label = train_set[0]\n",
        "print('訓練データの件数:', len(train_set))\n",
        "print('訓練データの型：', type(image))\n",
        "print('訓練データのshape：', image.shape)\n",
        "print('最小値：', image.data.min())\n",
        "print('最大値：', image.data.max())\n",
        "\n",
        "image, label = test_set[0]\n",
        "print('検証データの件数:', len(test_set))\n",
        "print('検証データの型：', type(image))\n",
        "print('検証データのshape：', image.shape)\n",
        "print('最小値：', image.data.min())\n",
        "print('最大値：', image.data.max())\n",
        "\n",
        "# 訓練用データローダー\n",
        "# 訓練用なので、シャッフルをかける\n",
        "train_loader = DataLoader(\n",
        "    train_set,\n",
        "    batch_size = batch_size,\n",
        "    shuffle = True,\n",
        ")\n",
        "# 検証用データローダー\n",
        "# 検証用にシャッフルは不要\n",
        "test_loader = DataLoader(\n",
        "    test_set,\n",
        "    batch_size = batch_size,\n",
        "    shuffle = False,\n",
        ")\n",
        "\n",
        "# データローダーの最初の１セットから、データの次元数を取得\n",
        "inputs, labels = next(iter(train_loader))\n",
        "# 入力次元数\n",
        "n_input = inputs.shape[1] # 0:ミニバッチサイズ、1:入力次元数\n",
        "# 出力次元数\n",
        "n_output = dim_output\n",
        "# 隠れ層の次元数\n",
        "n_hidden = dim_hidden\n",
        "print(f'入力次元数：{n_input}')\n",
        "print(f'出力次元数：{n_output}')\n",
        "print(f'隠れ層の次元数：{n_hidden}')\n",
        "\n",
        "###################################################\n",
        "# 関数定義\n",
        "###################################################\n",
        "class Net(torch.nn.Module):\n",
        "    def __init__(self, n_input, n_output, n_hidden):\n",
        "        super().__init__()\n",
        "        # 予測関数\n",
        "        self.conv1 = torch.nn.Conv2d(3, 32, 3)\n",
        "        self.conv2 = torch.nn.Conv2d(32, 32, 3)\n",
        "        # ReLU関数\n",
        "        self.relu = torch.nn.ReLU(inplace=True)\n",
        "        # MaxPool関数\n",
        "        self.maxpool = torch.nn.MaxPool2d((2, 2))\n",
        "\n",
        "    # 予測関数\n",
        "    def forward(self, inputs):\n",
        "      self.net = self.torch.nn.Sequential(\n",
        "          self.conv1,\n",
        "          self.relu,\n",
        "          self.conv2,\n",
        "          self.relu,\n",
        "          self.maxpool,\n",
        "      )\n",
        "      return self.net(inputs)\n",
        "\n",
        "# ###########################\n",
        "# # メイン処理\n",
        "# ###########################\n",
        "# num_data = len(train_loader)\n",
        "# num_data_test = len(test_loader)\n",
        "# print('# 訓練・検証')\n",
        "# print('入力層の次元数:', n_input)\n",
        "# print('中間層の次元数:', n_hidden)\n",
        "# print('出力層の次元数:', n_output)\n",
        "# print('バッチ繰返回数:', num_epochs)\n",
        "# print('ミニバッチサイズ:', batch_size)\n",
        "# print('ミニバッチ回数（訓練）:', num_data)\n",
        "# print('ミニバッチ回数（検証）:', num_data_test)\n",
        "\n",
        "# start_time = datetime.now()\n",
        "# # 予測計算オブジェクトの作成\n",
        "# net = Net(n_input, n_output, n_hidden, num_layer).to(device)\n",
        "# # 損失関数\n",
        "# criterion = torch.nn.CrossEntropyLoss()\n",
        "# # 最適化関数\n",
        "# optimizer = torch.optim.SGD(net.parameters(), lr=lr)\n",
        "# # 記録用配列初期化()\n",
        "# history = np.zeros((0, 5))\n",
        "\n",
        "# # 訓練＆検証\n",
        "# for epoch in range(num_epochs):\n",
        "#   ###########################\n",
        "#   # 履歴保存用変数\n",
        "#   ###########################\n",
        "#   # １エポック当たりの正解データ累積件数\n",
        "#   n_cum_train_acc = 0\n",
        "#   n_cum_test_acc = 0\n",
        "#   # １エポック当たりの累積損失（平均化前）\n",
        "#   cum_train_loss = 0\n",
        "#   cum_test_loss = 0\n",
        "#   # １エポック当たりのデータ累積件数\n",
        "#   n_cum_train = 0\n",
        "#   n_cum_test = 0\n",
        "\n",
        "#   ###########################\n",
        "#   # 学習\n",
        "#   ###########################\n",
        "#   for idx, (inputs, labels) in enumerate(tqdm(train_loader)):\n",
        "#     # 入力データをデバイスへ転送\n",
        "#     inputs = inputs.to(device)\n",
        "#     labels = labels.to(device)\n",
        "#     # 予測計算\n",
        "#     outputs = net(inputs)\n",
        "#     # 損失計算\n",
        "#     loss = criterion(outputs, labels)\n",
        "#     # 最初の１回のみ、計算グラフ（予測、損失）を描画\n",
        "#     if epoch == 0 and idx == 0:\n",
        "#         g = make_dot(loss, params = dict(net.named_parameters()))\n",
        "#         display(g)\n",
        "#     # 勾配計算\n",
        "#     loss.backward()\n",
        "#     # パラメータ調整\n",
        "#     optimizer.step()\n",
        "#     # 勾配クリア\n",
        "#     optimizer.zero_grad()\n",
        "#     # 損失の保存（スカラー値の取得）\n",
        "#     train_loss = loss.item()\n",
        "#     # 予測データ（0, 1, ... ,9）計算\n",
        "#     predicted = torch.max(outputs, 1)\n",
        "\n",
        "#     # １バッチ当たりのデータ件数\n",
        "#     train_batch_size = len(labels)\n",
        "#     # １エポック当たりのデータ累積件数\n",
        "#     n_cum_train += train_batch_size\n",
        "#     # 正解数の保存\n",
        "#     n_train_acc = (predicted.indices == labels).sum()\n",
        "#     # １エポック当たりの累積正解数\n",
        "#     n_cum_train_acc += n_train_acc\n",
        "#     # １エポック当たりの累積損失（平均化前）\n",
        "#     cum_train_loss += train_loss * train_batch_size\n",
        "\n",
        "#   ###########################\n",
        "#   # 検証\n",
        "#   ###########################\n",
        "#   for inputs_test, labels_test in tqdm(test_loader):\n",
        "#     # 入力データをデバイスへ転送\n",
        "#     inputs_test = inputs_test.to(device)\n",
        "#     labels_test = labels_test.to(device)\n",
        "#     # 予測計算\n",
        "#     outputs_test = net(inputs_test)\n",
        "#     # 損失計算\n",
        "#     loss = criterion(outputs_test, labels_test)\n",
        "#     # 損失の保存（スカラー値の取得）\n",
        "#     test_loss = loss.item()\n",
        "#     # 予測データ（0, 1, ... ,9）計算\n",
        "#     predicted_test = torch.max(outputs_test, 1)\n",
        "\n",
        "#     # １バッチ当たりのデータ件数\n",
        "#     test_batch_size = len(labels_test)\n",
        "#     # １エポック当たりのデータ累積件数\n",
        "#     n_cum_test += test_batch_size\n",
        "#     # 正解数の保存\n",
        "#     n_test_acc = (predicted_test.indices == labels_test).sum()\n",
        "#     # １エポック当たりの累積正解数\n",
        "#     n_cum_test_acc += n_test_acc\n",
        "#     # １エポック当たりの累積損失（平均化前）\n",
        "#     cum_test_loss += test_loss * test_batch_size\n",
        "\n",
        "#   ###########################\n",
        "#   # 履歴を保存\n",
        "#   ###########################\n",
        "#   item = np.array([\n",
        "#     epoch,\n",
        "#     cum_train_loss / n_cum_train,\n",
        "#     (n_cum_train_acc / n_cum_train).cpu(),\n",
        "#     cum_test_loss / n_cum_test,\n",
        "#     (n_cum_test_acc / n_cum_test).cpu(),\n",
        "#   ])\n",
        "#   history = np.vstack((history, item))\n",
        "\n",
        "# end_time = datetime.now()\n",
        "# td = end_time - start_time\n",
        "# total_us = td.seconds * 1_000_000 + td.microseconds\n",
        "# h = total_us // (3600 * 1_000_000)\n",
        "# m = (total_us // (60 * 1_000_000)) % 60\n",
        "# s = (total_us // 1_000_000) % 60\n",
        "# us = total_us % 1_000_000\n",
        "# print(f'開始　　{start_time.strftime(\"%H:%M:%S.%f\")}')\n",
        "# print(f'終了　　{end_time.strftime(\"%H:%M:%S.%f\")}')\n",
        "# print(f'処理　　{h:02}:{m:02}:{s:02}.{us:06}')\n",
        "\n",
        "# ###############################################\n",
        "# # 結果表示\n",
        "# ###############################################\n",
        "# # 損失と精度の確認\n",
        "# print(f'初期状態: 損失: {history[ 0, 3]:.5f} 精度: {history[ 0, 4]:.5f}')\n",
        "# print(f'最終状態: 損失: {history[-1, 3]:.5f} 精度: {history[-1, 4]:.5f}')\n",
        "\n",
        "# # 学習曲線グラフ（損失）\n",
        "# plt.plot(history[:, 0], history[:, 1], 'b', label='学習')\n",
        "# plt.plot(history[:, 0], history[:, 3], 'k', label='検証')\n",
        "# plt.xlabel('回数')\n",
        "# plt.ylabel('損失')\n",
        "# plt.title('学習曲線グラフ（損失）')\n",
        "# plt.legend()\n",
        "# plt.show()\n",
        "\n",
        "# # 学習曲線グラフ（精度）\n",
        "# plt.plot(history[:, 0], history[:, 2], 'b', label='学習')\n",
        "# plt.plot(history[:, 0], history[:, 4], 'k', label='検証')\n",
        "# plt.xlabel('回数')\n",
        "# plt.ylabel('精度')\n",
        "# plt.title('学習曲線グラフ（精度）')\n",
        "# plt.legend()\n",
        "# plt.show()\n",
        "\n",
        "# #######################################################\n",
        "# # 予測・正解サンプリング\n",
        "# # 正解データ付きで、最初のX0個をイメージ表示\n",
        "# #######################################################\n",
        "# # 画像データを取り直し\n",
        "# img_set = datasets.CIFAR10(\n",
        "#   root = data_root,\n",
        "#   train = False,\n",
        "#   download = True,\n",
        "# )\n",
        "# # 検証データを最初の500件だけ再計算\n",
        "# inputs_test, labels_test = next(iter(test_loader))\n",
        "# # 入力データをデバイスへ転送\n",
        "# inputs_test = inputs_test.to(device)\n",
        "# labels_test = labels_test.to(device)\n",
        "# # 予測計算\n",
        "# outputs_test = net(inputs_test)\n",
        "# # 予測データ（0, 1, ... ,9）計算\n",
        "# predicted_test = torch.max(outputs_test, 1)\n",
        "\n",
        "# # 最初のROW_NUM×COL_NUM件だけ、予測・正解データ付きでイメージを表示\n",
        "# ROW_NUM = 5\n",
        "# COL_NUM = 10\n",
        "# fig = plt.figure(figsize=(COL_NUM, ROW_NUM + 1))\n",
        "# plt.suptitle('予測:正解')\n",
        "# for i in range(COL_NUM * ROW_NUM):\n",
        "#   image, label = img_set[i]\n",
        "#   ax = plt.subplot(ROW_NUM, COL_NUM, i + 1)\n",
        "#   # イメージ表示\n",
        "#   plt.imshow(image)\n",
        "#   ax.set_title(f'{predicted_test.indices[i]}:{label}')\n",
        "#   ax.get_xaxis().set_visible(False)\n",
        "#   ax.get_yaxis().set_visible(False)\n",
        "# plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "SQjHJyKHuPFt",
        "outputId": "25914ec1-c662-4f47-e508-b98e089444db"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda:0\n",
            "# 入力データの確認\n",
            "訓練データの件数: 50000\n",
            "訓練データの型： <class 'torch.Tensor'>\n",
            "訓練データのshape： torch.Size([3, 32, 32])\n",
            "最小値： tensor(-1.)\n",
            "最大値： tensor(1.)\n",
            "検証データの件数: 10000\n",
            "検証データの型： <class 'torch.Tensor'>\n",
            "検証データのshape： torch.Size([3, 32, 32])\n",
            "最小値： tensor(-0.8980)\n",
            "最大値： tensor(1.)\n",
            "入力次元数：3\n",
            "出力次元数：10\n",
            "隠れ層の次元数：128\n"
          ]
        }
      ]
    }
  ]
}
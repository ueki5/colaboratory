{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNJzfsrhAq9Mqwo+7x+a2KU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ueki5/colaboratory/blob/main/playground-019.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchviz | tail -n 1\n",
        "!pip install torchinfo | tail -n 1\n",
        "!pip install japanize-matplotlib | tail -n 1\n",
        "!pip install plotly | tail -n 1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ljFG6GVDBoaC",
        "outputId": "748cb162-f93e-4f44-89f4-f751cb155f60"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully installed torchviz-0.0.3\n",
            "Successfully installed torchinfo-1.8.0\n",
            "Successfully installed japanize-matplotlib-1.1.3\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from plotly) (25.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.transforms as transforms\n",
        "import japanize_matplotlib\n",
        "japanize_matplotlib.japanize()\n",
        "from torch.utils.data import DataLoader\n",
        "from datetime import datetime\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "# 各種定数\n",
        "batch_size = 500 # ミニバッチのサイズ指定\n",
        "num_epochs = 10 # 繰り返し回数\n",
        "lr = 0.01  # 学習率\n",
        "dim_hidden = 128 # 隠れ層の次元数\n",
        "dim_output = 10 # 出力層の次元数\n",
        "num_layer = 2 # レイヤー数\n",
        "use_cuda = True # CUDA使用\n",
        "\n",
        "# デバイスの割り当て\n",
        "if use_cuda:\n",
        "  device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "else:\n",
        "  device = torch.device(\"cpu\")\n",
        "print(device)\n",
        "\n",
        "# ダウンロード先ディレクトリ名\n",
        "data_root = './data'\n",
        "\n",
        "#######################################################\n",
        "# 予測・正解サンプリング\n",
        "#######################################################\n",
        "# 正解データ付きで、最初のX0個をイメージ表示\n",
        "\n",
        "# テンソル化 ＋ 正規化 ＋ １階テンソル化\n",
        "transform = transforms.Compose([\n",
        "  # データのテンソル化\n",
        "  transforms.ToTensor(),\n",
        "  # データの正規化(Normalize(μ, σ) ⇒ (x - μ) / σ)\n",
        "  transforms.Normalize(0.5, 0.5),\n",
        "  # １階テンソル化\n",
        "  # transforms.Lambda(lambda x: x.view(-1)),\n",
        "])\n",
        "\n",
        "img_set = datasets.CIFAR10(\n",
        "  root = data_root,\n",
        "  train = False,\n",
        "  download = True,\n",
        ")\n",
        "test_set = datasets.CIFAR10(\n",
        "  root=data_root,\n",
        "  train=False,\n",
        "  download=True,\n",
        "  transform=transform,\n",
        ")\n",
        "test_loader = DataLoader(\n",
        "    test_set,\n",
        "    batch_size = batch_size,\n",
        "    shuffle = False,\n",
        ")\n",
        "inputs_test, labels_test = next(iter(test_loader))\n",
        "# 入力データをデバイスへ転送\n",
        "inputs_test = inputs_test.to(device)\n",
        "labels_test = labels_test.to(device)\n",
        "# 予測計算\n",
        "outputs_test = net(inputs_test)\n",
        "# 損失計算\n",
        "loss = criterion(outputs_test, labels_test)\n",
        "# 損失の保存（スカラー値の取得）\n",
        "test_loss = loss.item()\n",
        "# 予測データ（0, 1, ... ,9）計算\n",
        "predicted_test = torch.max(outputs_test, 1)\n",
        "print('predicted_test.indices:', len(predicted_test.indices))\n",
        "\n",
        "# 最初の要素の取得\n",
        "ROW_NUM = 5\n",
        "COL_NUM = 10\n",
        "fig = plt.figure(figsize=(COL_NUM, ROW_NUM + 1))\n",
        "plt.suptitle('予測:正解')\n",
        "for i in range(COL_NUM * ROW_NUM):\n",
        "  image, label = img_set[i]\n",
        "  ax = plt.subplot(ROW_NUM, COL_NUM, i + 1)\n",
        "  # イメージ表示\n",
        "  plt.imshow(image, cmap='gray_r')\n",
        "  ax.set_title(f'{predicted_test.indices[i]}:{label}')\n",
        "  ax.get_xaxis().set_visible(False)\n",
        "  ax.get_yaxis().set_visible(False)\n",
        "plt.show()\n",
        "\n",
        "# # テンソル化 ＋ 正規化 ＋ １階テンソル化\n",
        "# transform = transforms.Compose([\n",
        "#   # データのテンソル化\n",
        "#   transforms.ToTensor(),\n",
        "#   # データの正規化(Normalize(μ, σ) ⇒ (x - μ) / σ)\n",
        "#   transforms.Normalize(0.5, 0.5),\n",
        "#   # １階テンソル化\n",
        "#   transforms.Lambda(lambda x: x.view(-1)),\n",
        "# ])\n",
        "\n",
        "# # 訓練データ\n",
        "# train_set = datasets.CIFAR10(\n",
        "#   root=data_root,\n",
        "#   train=True,\n",
        "#   download=True,\n",
        "#   transform=transform\n",
        "# )\n",
        "\n",
        "# # 検証データ\n",
        "# test_set = datasets.CIFAR10(\n",
        "#   root=data_root,\n",
        "#   train=False,\n",
        "#   download=True,\n",
        "#   transform=transform\n",
        "# )\n",
        "# # 変換結果の確認\n",
        "# image, label = train_set[0]\n",
        "# print('訓練データの型：', type(image))\n",
        "# print('訓練データのshape：', image.shape)\n",
        "# print('最小値：', image.data.min())\n",
        "# print('最大値：', image.data.max())\n",
        "\n",
        "# image, label = test_set[0]\n",
        "# print('検証データの型：', type(image))\n",
        "# print('検証データのshape：', image.shape)\n",
        "# print('最小値：', image.data.min())\n",
        "# print('最大値：', image.data.max())\n",
        "\n",
        "# # 訓練用データローダー\n",
        "# # 訓練用なので、シャッフルをかける\n",
        "# train_loader = DataLoader(\n",
        "#     train_set,\n",
        "#     batch_size = batch_size,\n",
        "#     shuffle = True,\n",
        "# )\n",
        "\n",
        "# # 検証用データローダー\n",
        "# # 検証用にシャッフルは不要\n",
        "# test_loader = DataLoader(\n",
        "#     test_set,\n",
        "#     batch_size = batch_size,\n",
        "#     shuffle = False,\n",
        "# )\n",
        "\n",
        "# # 何組のデータが取得できるか？\n",
        "# num_data = len(train_loader)\n",
        "# num_data_test = len(test_loader)\n",
        "# print(f'num_data:{num_data},num_data_test:{num_data_test}')\n",
        "\n",
        "# # データローダーから最初の１セットを取得する\n",
        "# inputs, labels = next(iter(train_loader))\n",
        "# print('inputs.shape:', inputs.shape)\n",
        "# print('labels.shape:', labels.shape)\n",
        "\n",
        "# # 入力次元数\n",
        "# n_input = inputs.shape[1] # 0:ミニバッチサイズ、1:入力次元数\n",
        "\n",
        "# # 出力次元数\n",
        "# n_output = dim_output\n",
        "\n",
        "# # 隠れ層の次元数\n",
        "# n_hidden = dim_hidden\n",
        "\n",
        "# # 結果確認\n",
        "# print(f'n_input: {n_input}, n_hidden: {n_hidden}, n_output: {n_output}')\n",
        "\n",
        "# ###################################################\n",
        "# # 関数定義\n",
        "# ###################################################\n",
        "# class Net(torch.nn.Module):\n",
        "#     def __init__(self, n_input, n_output, n_hidden, n_layer):\n",
        "#         super().__init__()\n",
        "\n",
        "#         # 予測関数\n",
        "#         layers = []\n",
        "#         for i in range(n_layer):\n",
        "#             _n_input = n_hidden\n",
        "#             _n_output = n_hidden\n",
        "#             if i == 0:\n",
        "#                 _n_input = n_input\n",
        "#             if i == n_layer - 1:\n",
        "#                 _n_output = n_output\n",
        "#             print(f'in={_n_input}, out={_n_output}')\n",
        "#             layers.append(torch.nn.Linear(_n_input, _n_output))\n",
        "#         self.layers = torch.nn.ModuleList(layers)\n",
        "\n",
        "#         # ReLU関数\n",
        "#         self.relu = torch.nn.ReLU(inplace=True)\n",
        "\n",
        "#     # 予測関数\n",
        "#     def forward(self, inputs):\n",
        "#       x = self.layers[0](inputs)\n",
        "#       for layer in self.layers[1:]:\n",
        "#         x = self.relu(x)\n",
        "#         x = layer(x)\n",
        "#       return x\n",
        "\n",
        "# start_time = datetime.now()\n",
        "# # 予測計算オブジェクトの作成\n",
        "# net = Net(n_input, n_output, n_hidden, num_layer).to(device)\n",
        "\n",
        "# # 損失関数\n",
        "# criterion = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "# # 最適化関数\n",
        "# optimizer = torch.optim.SGD(net.parameters(), lr=lr)\n",
        "\n",
        "# # 記録用配列初期化()\n",
        "# history = np.zeros((0, 5))\n",
        "\n",
        "# # 学習＆検証\n",
        "# for epoch in range(num_epochs):\n",
        "#   ###########################\n",
        "#   # 履歴保存用変数\n",
        "#   ###########################\n",
        "#   # １エポック当たりの正解データ累積件数\n",
        "#   n_cum_train_acc = 0\n",
        "#   n_cum_test_acc = 0\n",
        "#   # １エポック当たりの累積損失（平均化前）\n",
        "#   cum_train_loss = 0\n",
        "#   cum_test_loss = 0\n",
        "#   # １エポック当たりのデータ累積件数\n",
        "#   n_cum_train = 0\n",
        "#   n_cum_test = 0\n",
        "\n",
        "#   ###########################\n",
        "#   # 学習\n",
        "#   ###########################\n",
        "#   for inputs, labels in tqdm(train_loader):\n",
        "#     # 入力データをデバイスへ転送\n",
        "#     inputs = inputs.to(device)\n",
        "#     labels = labels.to(device)\n",
        "\n",
        "#     # １バッチ当たりのデータ件数\n",
        "#     train_batch_size = len(labels)\n",
        "#     # １エポック当たりのデータ累積件数\n",
        "#     n_cum_train += train_batch_size\n",
        "\n",
        "#     # 予測計算\n",
        "#     outputs = net(inputs)\n",
        "\n",
        "#     # 損失計算\n",
        "#     loss = criterion(outputs, labels)\n",
        "\n",
        "#     # 勾配計算\n",
        "#     loss.backward()\n",
        "\n",
        "#     # パラメータ調整\n",
        "#     optimizer.step()\n",
        "\n",
        "#     # 勾配クリア\n",
        "#     optimizer.zero_grad()\n",
        "\n",
        "#     # 損失の保存（スカラー値の取得）\n",
        "#     train_loss = loss.item()\n",
        "\n",
        "#     # 予測データ（0, 1, ... ,9）計算\n",
        "#     predicted = torch.max(outputs, 1)\n",
        "\n",
        "#     # 正解数の保存\n",
        "#     n_train_acc = (predicted.indices == labels).sum()\n",
        "\n",
        "#     # １エポック当たりの累積正解数\n",
        "#     n_cum_train_acc += n_train_acc\n",
        "\n",
        "#     # １エポック当たりの累積損失（平均化前）\n",
        "#     cum_train_loss += train_loss * train_batch_size\n",
        "\n",
        "#   ###########################\n",
        "#   # 検証\n",
        "#   ###########################\n",
        "#   for inputs_test, labels_test in tqdm(test_loader):\n",
        "#     # 入力データをデバイスへ転送\n",
        "#     inputs_test = inputs_test.to(device)\n",
        "#     labels_test = labels_test.to(device)\n",
        "#     # １バッチ当たりのデータ件数\n",
        "#     test_batch_size = len(labels_test)\n",
        "#     # １エポック当たりのデータ累積件数\n",
        "#     n_cum_test += test_batch_size\n",
        "\n",
        "#     # 予測計算\n",
        "#     outputs_test = net(inputs_test)\n",
        "\n",
        "#     # 損失計算\n",
        "#     loss = criterion(outputs_test, labels_test)\n",
        "\n",
        "#     # 損失の保存（スカラー値の取得）\n",
        "#     test_loss = loss.item()\n",
        "\n",
        "#     # 予測データ（0, 1, ... ,9）計算\n",
        "#     predicted_test = torch.max(outputs_test, 1)\n",
        "\n",
        "#     # 正解数の保存\n",
        "#     n_test_acc = (predicted_test.indices == labels_test).sum()\n",
        "\n",
        "#     # １エポック当たりの累積正解数\n",
        "#     n_cum_test_acc += n_test_acc\n",
        "\n",
        "#     # １エポック当たりの累積損失（平均化前）\n",
        "#     cum_test_loss += test_loss * test_batch_size\n",
        "\n",
        "#   ###########################\n",
        "#   # 履歴を保存\n",
        "#   ###########################\n",
        "#   item = np.array([\n",
        "#     epoch,\n",
        "#     cum_train_loss / n_cum_train,\n",
        "#     (n_cum_train_acc / n_cum_train).cpu(),\n",
        "#     cum_test_loss / n_cum_test,\n",
        "#     (n_cum_test_acc / n_cum_test).cpu(),\n",
        "#   ])\n",
        "#   history = np.vstack((history, item))\n",
        "\n",
        "# end_time = datetime.now()\n",
        "# td = end_time - start_time\n",
        "# total_us = td.seconds * 1_000_000 + td.microseconds\n",
        "# h = total_us // (3600 * 1_000_000)\n",
        "# m = (total_us // (60 * 1_000_000)) % 60\n",
        "# s = (total_us // 1_000_000) % 60\n",
        "# us = total_us % 1_000_000\n",
        "# print(f'開始　　{start_time.strftime(\"%H:%M:%S.%f\")}')\n",
        "# print(f'終了　　{end_time.strftime(\"%H:%M:%S.%f\")}')\n",
        "# print(f'処理　　{h:02}:{m:02}:{s:02}.{us:06}')\n",
        "\n",
        "# ###############################################\n",
        "# # 結果表示\n",
        "# ###############################################\n",
        "# # 損失と精度の確認\n",
        "# print(f'初期状態: 損失: {history[ 0, 3]:.5f} 精度: {history[ 0, 4]:.5f}')\n",
        "# print(f'最終状態: 損失: {history[-1, 3]:.5f} 精度: {history[-1, 4]:.5f}')\n",
        "\n",
        "# # 学習曲線グラフ（損失）\n",
        "# plt.plot(history[:, 0], history[:, 1], 'b', label='学習')\n",
        "# plt.plot(history[:, 0], history[:, 3], 'k', label='検証')\n",
        "# plt.xlabel('回数')\n",
        "# plt.ylabel('損失')\n",
        "# plt.title('学習曲線グラフ（損失）')\n",
        "# plt.legend()\n",
        "# plt.show()\n",
        "\n",
        "# # 学習曲線グラフ（精度）\n",
        "# plt.plot(history[:, 0], history[:, 2], 'b', label='学習')\n",
        "# plt.plot(history[:, 0], history[:, 4], 'k', label='検証')\n",
        "# plt.xlabel('回数')\n",
        "# plt.ylabel('精度')\n",
        "# plt.title('学習曲線グラフ（精度）')\n",
        "# plt.legend()\n",
        "# plt.show()\n",
        "\n",
        "# #######################################################\n",
        "# # 予測・正解サンプリング\n",
        "# #######################################################\n",
        "# # 正解データ付きで、最初のX0個をイメージ表示\n",
        "# img_set = datasets.MNIST(\n",
        "#   root = data_root,\n",
        "#   train = False,\n",
        "#   download = True,\n",
        "# )\n",
        "# test_set = datasets.MNIST(\n",
        "#   root=data_root,\n",
        "#   train=False,\n",
        "#   download=True,\n",
        "#   transform=transform,\n",
        "# )\n",
        "# test_loader = DataLoader(\n",
        "#     test_set,\n",
        "#     batch_size = batch_size,\n",
        "#     shuffle = False,\n",
        "# )\n",
        "# inputs_test, labels_test = next(iter(test_loader))\n",
        "# # 入力データをデバイスへ転送\n",
        "# inputs_test = inputs_test.to(device)\n",
        "# labels_test = labels_test.to(device)\n",
        "# # 予測計算\n",
        "# outputs_test = net(inputs_test)\n",
        "# # 損失計算\n",
        "# loss = criterion(outputs_test, labels_test)\n",
        "# # 損失の保存（スカラー値の取得）\n",
        "# test_loss = loss.item()\n",
        "# # 予測データ（0, 1, ... ,9）計算\n",
        "# predicted_test = torch.max(outputs_test, 1)\n",
        "# print('predicted_test.indices:', len(predicted_test.indices))\n",
        "\n",
        "# # 最初の要素の取得\n",
        "# ROW_NUM = 5\n",
        "# COL_NUM = 10\n",
        "# fig = plt.figure(figsize=(COL_NUM, ROW_NUM + 1))\n",
        "# plt.suptitle('予測:正解')\n",
        "# for i in range(COL_NUM * ROW_NUM):\n",
        "#   image, label = img_set[i]\n",
        "#   ax = plt.subplot(ROW_NUM, COL_NUM, i + 1)\n",
        "#   # イメージ表示\n",
        "#   plt.imshow(image, cmap='gray_r')\n",
        "#   ax.set_title(f'{predicted_test.indices[i]}:{label}')\n",
        "#   ax.get_xaxis().set_visible(False)\n",
        "#   ax.get_yaxis().set_visible(False)\n",
        "# plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SQjHJyKHuPFt",
        "outputId": "67bc03f3-eed8-419a-d829-6e135690d871"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda:0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170M/170M [00:19<00:00, 8.58MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "訓練データの型： <class 'torch.Tensor'>\n",
            "訓練データのshape： torch.Size([3072])\n",
            "最小値： tensor(-1.)\n",
            "最大値： tensor(1.)\n",
            "検証データの型： <class 'torch.Tensor'>\n",
            "検証データのshape： torch.Size([3072])\n",
            "最小値： tensor(-0.8980)\n",
            "最大値： tensor(1.)\n"
          ]
        }
      ]
    }
  ]
}
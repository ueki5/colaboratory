{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ueki5/colaboratory/blob/main/playground-017.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchviz | tail -n 1\n",
        "!pip install torchinfo | tail -n 1\n",
        "!pip install japanize-matplotlib | tail -n 1\n",
        "!pip install plotly | tail -n 1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5OCN-kKpZRUF",
        "outputId": "65f7be57-ce30-423c-f845-c82a8a6e1155"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch->torchviz) (3.0.3)\n",
            "Requirement already satisfied: torchinfo in /usr/local/lib/python3.12/dist-packages (1.8.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib->japanize-matplotlib) (1.17.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from plotly) (25.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "teUVqnbXqf4F",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 453
        },
        "outputId": "08226b74-df85-4c20-8702-aed31e834acf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "元データ (150, 4) (150,)\n",
            "対象データ (100, 2) (100, 2)\n",
            "学習データ： torch.Size([70, 2]) torch.Size([70, 2])\n",
            "検証データ： torch.Size([30, 2]) torch.Size([30, 2])\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "0D or 1D target tensor expected, multi-target not supported",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1089478983.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m   \u001b[0;31m# 損失計算\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m   \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m     \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_dot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnamed_parameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1772\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1773\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1782\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m   1308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1309\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1310\u001b[0;31m         return F.cross_entropy(\n\u001b[0m\u001b[1;32m   1311\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1312\u001b[0m             \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mcross_entropy\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[0m\n\u001b[1;32m   3460\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msize_average\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mreduce\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3461\u001b[0m         \u001b[0mreduction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_get_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize_average\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3462\u001b[0;31m     return torch._C._nn.cross_entropy_loss(\n\u001b[0m\u001b[1;32m   3463\u001b[0m         \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3464\u001b[0m         \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: 0D or 1D target tensor expected, multi-target not supported"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import plotly.express as px\n",
        "import matplotlib.pyplot as plt\n",
        "import japanize_matplotlib\n",
        "import torch\n",
        "from torchinfo import summary\n",
        "from torchviz import make_dot\n",
        "import plotly.graph_objects as go\n",
        "import plotly.express as px\n",
        "from plotly.subplots import make_subplots\n",
        "\n",
        "# データ準備\n",
        "from sklearn.datasets import load_iris\n",
        "\n",
        "# データ読み込み\n",
        "iris = load_iris()\n",
        "\n",
        "# 入力データと正解データ取得\n",
        "x_org, y_org = iris.data, iris.target\n",
        "\n",
        "# 結果確認\n",
        "print('元データ', x_org.shape, y_org.shape)\n",
        "\n",
        "# データ絞り込み\n",
        "#  クラス0,1のみ\n",
        "#  項目 sepal_lengthとsepal_widthのみ\n",
        "x_data = iris.data[:100, :2]\n",
        "y_data = np.array([[0, 1] if t == 0 else [1, 0] for t in iris.target[:100]])\n",
        "# print(y_data)\n",
        "\n",
        "# 結果確認\n",
        "print('対象データ', x_data.shape, y_data.shape)\n",
        "\n",
        "# 訓練データ、検証データに分割（シャッフルも同時に実施）\n",
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_test, y_train, y_test = train_test_split(\n",
        "    x_data, y_data, train_size=70, test_size=30,\n",
        "    random_state=123\n",
        ")\n",
        "\n",
        "###################################################\n",
        "# 関数定義\n",
        "###################################################\n",
        "lr = 0.01  # 学習率\n",
        "num_epochs = 10000 # 繰り返し回数\n",
        "num_history = 10 # 履歴採取タイミング\n",
        "\n",
        "# 学習データ\n",
        "inputs = torch.tensor(x_train).float()\n",
        "labels = torch.tensor(y_train).float()\n",
        "\n",
        "# 検証データ\n",
        "inputs_test = torch.tensor(x_test).float()\n",
        "labels_test = torch.tensor(y_test).float()\n",
        "print('学習データ：',inputs.data.shape, labels.data.shape)\n",
        "print('検証データ：',inputs_test.data.shape, labels_test.data.shape)\n",
        "\n",
        "# 予測計算クラス\n",
        "n_input = x_train.shape[1]\n",
        "n_output = 1\n",
        "class Net(torch.nn.Module):\n",
        "  # 初期化\n",
        "  def __init__(self, n_input, n_output):\n",
        "    super().__init__()\n",
        "    # 予測関数を生成\n",
        "    self.l1 = torch.nn.Linear(n_input, n_output) # 初段\n",
        "    # 重み、バイアスの初期値を設定\n",
        "    self.l1.weight.data.fill_(1.0)\n",
        "    self.l1.bias.data.fill_(1.0)\n",
        "\n",
        "    # 関数合成\n",
        "    self.net = torch.nn.Sequential(\n",
        "        self.l1,\n",
        "    )\n",
        "\n",
        "  # 予測関数\n",
        "  def forward(self, inputs):\n",
        "    outputs = self.net(inputs)\n",
        "    return outputs\n",
        "\n",
        "# 予測計算オブジェクト\n",
        "net = Net(n_input, n_output)\n",
        "\n",
        "# 損失関数\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "# 最適化関数\n",
        "optimizer = torch.optim.SGD(net.parameters(), lr=lr)\n",
        "\n",
        "# 記録用配列初期化\n",
        "history = np.zeros((0, 5))\n",
        "\n",
        "###################################################\n",
        "# 強化学習\n",
        "###################################################\n",
        "for epoch in range(num_epochs):\n",
        "\n",
        "  ###################################################\n",
        "  # 学習フェーズ\n",
        "  ###################################################\n",
        "  # 予測計算\n",
        "  outputs = net(inputs)\n",
        "\n",
        "  # 損失計算\n",
        "  loss = criterion(outputs, labels)\n",
        "  if epoch == 0:\n",
        "    g = make_dot(loss, params = dict(net.named_parameters()))\n",
        "    display(g)\n",
        "\n",
        "  # 勾配計算\n",
        "  loss.backward()\n",
        "\n",
        "  # パラメータ調整＆勾配クリア\n",
        "  optimizer.step()\n",
        "  optimizer.zero_grad()\n",
        "\n",
        "  # 損失の保存（スカラー値の取得）\n",
        "  train_loss = loss.item()\n",
        "\n",
        "  # 予測データ（0 or 1）計算\n",
        "  predicted = torch.where(outputs < 0.5, 0, 1)\n",
        "\n",
        "  # 精度計算\n",
        "  train_acc = (predicted == labels).sum() / len(y_train)\n",
        "\n",
        "  ###############################################\n",
        "  # 予測フェーズ\n",
        "  ###############################################\n",
        "  outputs_test = net(inputs_test)\n",
        "\n",
        "  # 損失計算\n",
        "  loss_test = criterion(outputs_test, labels_test)\n",
        "\n",
        "  # 損失の保存（スカラー値の取得）\n",
        "  train_loss_test = loss_test.item()\n",
        "\n",
        "  # 予測データ（0 or 1）計算\n",
        "  predicted_test = torch.where(outputs_test < 0.5, 0, 1)\n",
        "\n",
        "  # 精度計算\n",
        "  train_acc_test = (predicted_test == labels_test).sum() / len(y_test)\n",
        "\n",
        "  # 学習曲線データの登録\n",
        "  if epoch % num_history == 0:\n",
        "    item = np.array([epoch, train_loss, train_acc, train_loss_test, train_acc_test])\n",
        "    history = np.vstack((history, item))\n",
        "\n",
        "\n",
        "###############################################\n",
        "# 結果表示\n",
        "###############################################\n",
        "# 損失と精度の確認\n",
        "print(f'初期状態: 損失: {history[0, 3]:.5f} 精度: {history[0, 4]:.5f}')\n",
        "print(f'最終状態: 損失: {history[-1, 3]:.5f} 精度: {history[-1, 4]:.5f}')\n",
        "\n",
        "# 学習曲線グラフ（損失）\n",
        "plt.plot(history[:,0], history[:,1], 'b', label='訓練')\n",
        "plt.plot(history[:,0], history[:,3], 'k', label='検証')\n",
        "plt.xlabel('繰り返し回数')\n",
        "plt.ylabel('損失')\n",
        "plt.title('学習曲線（損失）')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# 学習曲線グラフ（精度）\n",
        "plt.plot(history[:,0], history[:,2], 'b', label='訓練')\n",
        "plt.plot(history[:,0], history[:,4], 'k', label='検証')\n",
        "plt.xlabel('繰り返し回数')\n",
        "plt.ylabel('精度')\n",
        "plt.title('学習曲線（精度）')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# 散布図の表示（訓練データ）\n",
        "x_t0 = x_train[y_train == 0]\n",
        "x_t1 = x_train[y_train == 1]\n",
        "zero = np.zeros(x_t0.shape[0])\n",
        "data1 = go.Scatter3d(x=x_t0[:,0], y=x_t0[:,1], z=zero,\n",
        "                    mode='markers',\n",
        "                    marker=dict(size=3, color='blue', opacity=0.3, symbol='circle', showscale=True),\n",
        "                    name='0(setosa)(訓)')\n",
        "data2 = go.Scatter3d(x=x_t1[:,0], y=x_t1[:,1], z=zero,\n",
        "                    mode='markers',\n",
        "                    marker=dict(size=3, color='red', opacity=0.3, symbol='circle', showscale=True),\n",
        "                    name='1(versicolor)(訓)')\n",
        "# 散布図の表示（予測データ）\n",
        "x_e0 = x_test[y_test == 0]\n",
        "x_e1 = x_test[y_test == 1]\n",
        "data3 = go.Scatter3d(x=x_e0[:,0], y=x_e0[:,1], z=zero,\n",
        "                    mode='markers',\n",
        "                    marker=dict(size=1, color='blue', opacity=0.8, symbol='diamond', showscale=True),\n",
        "                    name='0(setosa)(予)')\n",
        "data4 = go.Scatter3d(x=x_e1[:,0], y=x_e1[:,1], z=zero,\n",
        "                    mode='markers',\n",
        "                    marker=dict(size=1, color='red', opacity=0.8, symbol='diamond', showscale=True),\n",
        "                    name='1(versicolor)(予)')\n",
        "# 最終パラメータ表示\n",
        "print('weight: ', net.l1.weight)\n",
        "print('bias: ', net.l1.bias)\n",
        "# 予測平面の表示\n",
        "x = np.outer(np.linspace(4.0, 7.0, 30), np.ones(30))\n",
        "y = np.outer(np.linspace(2.0, 4.5, 30), np.ones(30)).T\n",
        "w1 = net.l1.weight.data[0][0].item()\n",
        "w2 = net.l1.weight.data[0][1].item()\n",
        "b = net.l1.bias.data[0].item()\n",
        "z = w1 * x + w2 * y + b\n",
        "data5 = go.Surface(x=x, y=y, z=z, opacity=0.5)\n",
        "fig = go.Figure()\n",
        "fig.add_trace(data1)\n",
        "fig.add_trace(data2)\n",
        "fig.add_trace(data3)\n",
        "fig.add_trace(data4)\n",
        "fig.add_trace(data5)\n",
        "# X軸タイトルを指定\n",
        "fig.update_xaxes(title=\"sepal_length\")\n",
        "fig.update_yaxes(title=\"sepal_width\") # Y軸タイトルを指定\n",
        "fig.update_layout(title=\"散布図（訓練データ、予測データ）と予測平面\") # グラフタイトルを設定\n",
        "fig.update_layout(showlegend=True) # 凡例を強制的に表示（デフォルトでは複数系列あると表示）\n",
        "fig.update_layout(width=1200, height=900) # 図の高さと幅を指定\n",
        "fig.update_layout(legend=dict(xanchor='center',\n",
        "                              yanchor='bottom',\n",
        "                              x=0.85,\n",
        "                              y=0.7,\n",
        "                              orientation='v',\n",
        "                              bgcolor='white',\n",
        "                              bordercolor='black',\n",
        "                              borderwidth=0.1,\n",
        "                              ))\n",
        "fig.show()"
      ]
    }
  ]
}
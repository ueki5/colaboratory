{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ueki5/colaboratory/blob/main/playground-018.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XigipcBhRmDs"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ljFG6GVDBoaC",
        "outputId": "4a1ef844-56fd-485f-b210-b48eadaf16e5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Successfully installed torchviz-0.0.3\n",
            "Successfully installed torchinfo-1.8.0\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch==2.9.0->torchvision) (3.0.3)\n",
            "Successfully installed japanize-matplotlib-1.1.3\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from plotly) (25.0)\n"
          ]
        }
      ],
      "source": [
        "%pip install torchviz | tail -n 1\n",
        "%pip install torchinfo | tail -n 1\n",
        "%pip install torchvision | tail -n 1\n",
        "%pip install japanize-matplotlib | tail -n 1\n",
        "%pip install plotly | tail -n 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 686
        },
        "id": "SQjHJyKHuPFt",
        "outputId": "7405af04-ef86-4004-c9df-46d6634dd1ff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cpu\n",
            "訓練データの型： <class 'torch.Tensor'>\n",
            "訓練データのshape： torch.Size([784])\n",
            "最小値： tensor(-1.)\n",
            "最大値： tensor(1.)\n",
            "検証データの型： <class 'torch.Tensor'>\n",
            "検証データのshape： torch.Size([784])\n",
            "最小値： tensor(-1.)\n",
            "最大値： tensor(1.)\n",
            "num_data:120,num_data_test:20\n",
            "inputs.shape: torch.Size([500, 784])\n",
            "labels.shape: torch.Size([500])\n",
            "n_input: 784, n_hidden: 128, n_output: 10\n",
            "in=784, out=128\n",
            "in=128, out=128\n",
            "in=128, out=128\n",
            "in=128, out=128\n",
            "in=128, out=10\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1862210300.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    240\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m   \u001b[0minputs_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter_test_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 242\u001b[0;31m   \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    243\u001b[0m     \u001b[0;31m###########################\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m     \u001b[0;31m# 学習\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    730\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    731\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 732\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    733\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    734\u001b[0m             if (\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    786\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    787\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 788\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    789\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    790\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     50\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torchvision/datasets/mnist.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 146\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_transform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1773\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1774\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1775\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1776\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1777\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1784\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1785\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1786\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1787\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1788\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, tensor)\u001b[0m\n\u001b[1;32m    275\u001b[0m             \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mNormalized\u001b[0m \u001b[0mTensor\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m         \"\"\"\n\u001b[0;32m--> 277\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    278\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torchvision/transforms/functional.py\u001b[0m in \u001b[0;36mnormalize\u001b[0;34m(tensor, mean, std, inplace)\u001b[0m\n\u001b[1;32m    348\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"img should be Tensor Image. Got {type(tensor)}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 350\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mF_t\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmean\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    351\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    352\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torchvision/transforms/_functional_tensor.py\u001b[0m in \u001b[0;36mnormalize\u001b[0;34m(tensor, mean, std, inplace)\u001b[0m\n\u001b[1;32m    915\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 917\u001b[0;31m         \u001b[0mtensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    918\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m     \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.transforms as transforms\n",
        "import japanize_matplotlib\n",
        "japanize_matplotlib.japanize()\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# 各種定数\n",
        "batch_size = 500 # ミニバッチのサイズ指定\n",
        "lr = 0.01  # 学習率\n",
        "num_epochs = 5 # 繰り返し回数\n",
        "# num_history = 10 # 履歴採取タイミング\n",
        "dim_hidden = 128 # 隠れ層の次元数\n",
        "dim_output = 10 # 出力層の次元数\n",
        "num_layer = 5 # レイヤー数\n",
        "\n",
        "# デバイスの割り当て\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)\n",
        "\n",
        "# ダウンロード先ディレクトリ名\n",
        "data_root = './data'\n",
        "\n",
        "# # ReLU関数\n",
        "# relu = torch.nn.ReLU()\n",
        "# x_np = np.arange(-2, 2.1, 0.25)\n",
        "# x = torch.tensor(x_np).float()\n",
        "# y = relu(x)\n",
        "\n",
        "# plt.plot(x.data, y.data)\n",
        "# plt.title('ReLU関数')\n",
        "# plt.show()\n",
        "\n",
        "# # テスト用テンソル変数x, y\n",
        "# x_np = np.arange(-2, 2.1, 0.25)\n",
        "# y_np = np.arange(-1, 3.1, 0.25)\n",
        "# x = torch.tensor(x_np).float()\n",
        "# y = torch.tensor(y_np).float()\n",
        "\n",
        "# # 変数xをGPUに送る\n",
        "# x = x.to(device)\n",
        "# y = y.to(device)\n",
        "\n",
        "# # 変数xとyのdevice属性の確認\n",
        "# print('x:', x.device)\n",
        "# print('y:', y.device)\n",
        "\n",
        "# # xとyの間の演算\n",
        "# z = x * y\n",
        "# print(z)\n",
        "\n",
        "# train_set0 = datasets.MNIST(\n",
        "#     # 元データダウンロード先の指定\n",
        "#     root = data_root,\n",
        "#     # 訓練データか検証データか\n",
        "#     train = True,\n",
        "#     # 元データがない場合にダウンロードするか\n",
        "#     download = True)\n",
        "\n",
        "# # ダウンロードしたファイルの確認\n",
        "# !ls -lR ./data/MNIST\n",
        "\n",
        "# # データ件数の確認\n",
        "# print('train_set0.data.shape：', train_set0.data.shape)\n",
        "# print('データ件数：', len(train_set0))\n",
        "\n",
        "# # 最初の要素の取得\n",
        "# image, label = train_set0[0]\n",
        "\n",
        "# # データ型の確認\n",
        "# print('入力データの型：', type(image))\n",
        "# print('正解データの型：', type(label))\n",
        "# print(f'image.format:{image.format}')\n",
        "# print(f'image.size:{image.size}')\n",
        "# print(f'image.mode:{image.mode}')\n",
        "# print(f'image.getextrema:{image.getextrema()}')\n",
        "# for i in range(image.size[0]):\n",
        "#   for j in range(image.size[1]):\n",
        "#     print(f'image.getpixel(({i},{j})):{image.getpixel((i, j))}')\n",
        "\n",
        "# # 入力データの画像表示\n",
        "# plt.figure(figsize=(1, 1))\n",
        "# plt.title(f'{label}')\n",
        "# plt.imshow(image, cmap='gray_r')\n",
        "# plt.axis('off')\n",
        "# plt.show()\n",
        "\n",
        "# # 正解データ付きで、最初の２０個をイメージ表示\n",
        "# plt.figure(figsize=(10, 3))\n",
        "# for i in range(20):\n",
        "#   ax = plt.subplot(2, 10, i + 1)\n",
        "\n",
        "#   # imageとlabelの所得\n",
        "#   image, label = train_set0[i]\n",
        "\n",
        "#   # イメージ表示\n",
        "#   plt.imshow(image, cmap='gray_r')\n",
        "#   ax.set_title(f'{label}')\n",
        "#   ax.get_xaxis().set_visible(False)\n",
        "#   ax.get_yaxis().set_visible(False)\n",
        "# plt.show()\n",
        "\n",
        "# テンソル化 ＋ 正規化 ＋ １階テンソル化\n",
        "transform = transforms.Compose([\n",
        "  # データのテンソル化\n",
        "  transforms.ToTensor(),\n",
        "  # データの正規化(Normalize(μ, σ) ⇒ (x - μ) / σ)\n",
        "  transforms.Normalize(0.5, 0.5),\n",
        "  # １階テンソル化\n",
        "  transforms.Lambda(lambda x: x.view(-1)),\n",
        "])\n",
        "\n",
        "# 訓練データ\n",
        "train_set = datasets.MNIST(\n",
        "  root=data_root,\n",
        "  train=True,\n",
        "  download=True,\n",
        "  transform=transform\n",
        ")\n",
        "\n",
        "# 検証データ\n",
        "test_set = datasets.MNIST(\n",
        "  root=data_root,\n",
        "  train=False,\n",
        "  download=True,\n",
        "  transform=transform\n",
        ")\n",
        "# 変換結果の確認\n",
        "image, label = train_set[0]\n",
        "print('訓練データの型：', type(image))\n",
        "print('訓練データのshape：', image.shape)\n",
        "print('最小値：', image.data.min())\n",
        "print('最大値：', image.data.max())\n",
        "\n",
        "image, label = test_set[0]\n",
        "print('検証データの型：', type(image))\n",
        "print('検証データのshape：', image.shape)\n",
        "print('最小値：', image.data.min())\n",
        "print('最大値：', image.data.max())\n",
        "\n",
        "# 訓練用データローダー\n",
        "# 訓練用なので、シャッフルをかける\n",
        "train_loader = DataLoader(\n",
        "    train_set,\n",
        "    batch_size = batch_size,\n",
        "    shuffle = True,\n",
        ")\n",
        "\n",
        "# 検証用データローダー\n",
        "# 検証用にシャッフルは不要\n",
        "test_loader = DataLoader(\n",
        "    test_set,\n",
        "    batch_size = batch_size,\n",
        "    shuffle = False,\n",
        ")\n",
        "\n",
        "# 何組のデータが取得できるか？\n",
        "num_data = len(train_loader)\n",
        "num_data_test = len(test_loader)\n",
        "print(f'num_data:{num_data},num_data_test:{num_data_test}')\n",
        "\n",
        "# データローダーから最初の１セットを取得する\n",
        "inputs, labels = next(iter(train_loader))\n",
        "print('inputs.shape:', inputs.shape)\n",
        "print('labels.shape:', labels.shape)\n",
        "\n",
        "# 入力次元数\n",
        "n_input = inputs.shape[1] # 0:ミニバッチサイズ、1:入力次元数\n",
        "\n",
        "# 出力次元数\n",
        "n_output = dim_output\n",
        "\n",
        "# 隠れ層の次元数\n",
        "n_hidden = dim_hidden\n",
        "\n",
        "# 結果確認\n",
        "print(f'n_input: {n_input}, n_hidden: {n_hidden}, n_output: {n_output}')\n",
        "\n",
        "###################################################\n",
        "# 関数定義\n",
        "###################################################\n",
        "class Net(torch.nn.Module):\n",
        "    def __init__(self, n_input, n_output, n_hidden, n_layer):\n",
        "        super().__init__()\n",
        "\n",
        "        # 予測関数\n",
        "        layers = []\n",
        "        for i in range(n_layer):\n",
        "            _n_input = n_hidden\n",
        "            _n_output = n_hidden\n",
        "            if i == 0:\n",
        "                _n_input = n_input\n",
        "            if i == n_layer - 1:\n",
        "                _n_output = n_output\n",
        "            print(f'in={_n_input}, out={_n_output}')\n",
        "            layers.append(torch.nn.Linear(_n_input, _n_output))\n",
        "        self.layers = torch.nn.ModuleList(layers)\n",
        "        # self.l0 = torch.nn.Linear(n_input, n_output)\n",
        "        # self.l1 = torch.nn.Linear(n_input, n_hidden)\n",
        "        # self.l2 = torch.nn.Linear(n_hidden, n_hidden)\n",
        "        # self.l3 = torch.nn.Linear(n_hidden, n_output)\n",
        "\n",
        "        # ReLU関数\n",
        "        self.relu = torch.nn.ReLU(inplace=True)\n",
        "\n",
        "        # # 合成\n",
        "        # self.net = torch.nn.Sequential(\n",
        "        #     self.l1,\n",
        "        #     self.relu,\n",
        "        #     self.l2,\n",
        "        #     self.relu,\n",
        "        #     self.l3,\n",
        "        # )\n",
        "\n",
        "    # 予測関数\n",
        "    def forward(self, inputs):\n",
        "      x = self.layers[0](inputs)\n",
        "      for layer in self.layers[1:]:\n",
        "        x = self.relu(x)\n",
        "        x = layer(x)\n",
        "      return x\n",
        "      # return self.net(inputs)\n",
        "\n",
        "# 予測計算オブジェクトの作成\n",
        "net = Net(n_input, n_output, n_hidden, num_layer)\n",
        "\n",
        "# 損失関数\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "# 最適化関数\n",
        "optimizer = torch.optim.SGD(net.parameters(), lr=lr)\n",
        "\n",
        "# 記録用配列初期化()\n",
        "history = np.zeros((0, 5))\n",
        "\n",
        "# 学習＆検証\n",
        "iter_test_loader = iter(test_loader)\n",
        "for epoch in range(num_epochs):\n",
        "  inputs_test, labels_test = next(iter_test_loader)\n",
        "  for idx, (inputs, labels) in enumerate(train_loader):\n",
        "    ###########################\n",
        "    # 学習\n",
        "    ###########################\n",
        "    # 予測計算\n",
        "    outputs = net(inputs)\n",
        "\n",
        "    # 損失計算\n",
        "    loss = criterion(outputs, labels)\n",
        "\n",
        "    # 勾配計算\n",
        "    loss.backward()\n",
        "\n",
        "    # パラメータ調整\n",
        "    optimizer.step()\n",
        "\n",
        "    # 勾配クリア\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # 損失の保存（スカラー値の取得）\n",
        "    train_loss = loss.item()\n",
        "\n",
        "    # 予測データ（0, 1, ... ,9）計算\n",
        "    predicted = torch.max(outputs, 1)\n",
        "\n",
        "    # 精度計算\n",
        "    train_acc = (predicted.indices == labels).sum() / len(labels)\n",
        "\n",
        "    ###########################\n",
        "    # 検証\n",
        "    ###########################\n",
        "    # 予測計算\n",
        "    outputs_test = net(inputs_test)\n",
        "\n",
        "    # 損失計算\n",
        "    loss_test = criterion(outputs_test, labels_test)\n",
        "\n",
        "    # 損失の保存（スカラー値の取得）\n",
        "    train_loss_test = loss_test.item()\n",
        "\n",
        "    # 予測データ（0, 1, ... ,9）計算\n",
        "    predicted_test = torch.max(outputs_test, 1)\n",
        "\n",
        "    # 精度計算\n",
        "    train_acc_test = (predicted_test.indices == labels_test).sum() / len(labels_test)\n",
        "\n",
        "    # 履歴を保存\n",
        "    item = np.array([\n",
        "      epoch * num_data + idx,\n",
        "      train_loss,\n",
        "      train_acc,\n",
        "      train_loss_test,\n",
        "      train_acc_test,\n",
        "    ])\n",
        "    history = np.vstack((history, item))\n",
        "\n",
        "  # デバッグ用\n",
        "  if idx == num_data - 1:\n",
        "    pass\n",
        "\n",
        "###############################################\n",
        "# 結果表示\n",
        "###############################################\n",
        "# 損失と精度の確認\n",
        "# print('訓練回数:', history[:, 0])\n",
        "# print('訓練損失:', history[:, 1])\n",
        "# print('訓練精度:', history[:, 2])\n",
        "# print('検証回数:', history_test[:, 0])\n",
        "# print('検証損失:', history_test[:, 1])\n",
        "# print('検証精度:', history_test[:, 2])\n",
        "print(f'初期状態: 損失: {history_test[ 0, 1]:.5f} 精度: {history_test[ 0, 2]:.5f}')\n",
        "print(f'最終状態: 損失: {history_test[-1, 1]:.5f} 精度: {history_test[-1, 2]:.5f}')\n",
        "\n",
        "# 学習曲線グラフ（損失）\n",
        "plt.plot(history[:, 0], history[:, 1], 'b', label='学習')\n",
        "# plt.plot(history_test[:, 0], history_test[:, 1], 'k', label='検証')\n",
        "plt.xlabel('回数')\n",
        "plt.ylabel('損失')\n",
        "plt.title('学習曲線グラフ（損失）')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# 学習曲線グラフ（精度）\n",
        "plt.plot(history[:, 0], history[:, 2], 'b', label='学習')\n",
        "# plt.plot(history_test[:, 0], history_test[:, 2], 'k', label='検証')\n",
        "plt.xlabel('回数')\n",
        "plt.ylabel('精度')\n",
        "plt.title('学習曲線グラフ（精度）')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}